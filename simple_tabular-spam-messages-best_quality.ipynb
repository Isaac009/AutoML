{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\"\"\" Example script for predicting columns of tables, demonstrating simple use-case \"\"\"\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "\n",
    "# Training time:\n",
    "train_data = TabularDataset('./datasets/spam-message-train.csv')  # can be local CSV file as well, returns Pandas DataFrame\n",
    "train_data = train_data.head(500)  # subsample for faster demo\n",
    "print(train_data.head())\n",
    "label = 'class'  # specifies which column do we want to predict\n",
    "save_path = 'spam_message_ms/'  # where to save trained models\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  class                                            Message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "predictor = TabularPredictor(label=label, path=save_path).fit(train_data, time_limit=3600, presets='best_quality')\n",
    "# NOTE: Default settings above are intended to ensure reasonable runtime at the cost of accuracy. To maximize predictive accuracy, do this instead:\n",
    "# predictor = TabularPredictor(label=label, eval_metric=YOUR_METRIC_NAME, path=save_path).fit(train_data, presets='best_quality')\n",
    "results = predictor.fit_summary()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"spam_message_ms/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 1\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['ham', 'spam']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = spam, class 0 = ham\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (spam) vs negative (ham) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    498522.53 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.07 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Message']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 28\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('object', ['text']) : 1 | ['Message']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['Message']\n",
      "\t\t('int', ['binned', 'text_special']) : 34 | ['Message.char_count', 'Message.word_count', 'Message.capital_ratio', 'Message.lower_ratio', 'Message.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 29 | ['__nlp__.and', '__nlp__.are', '__nlp__.but', '__nlp__.call', '__nlp__.can', ...]\n",
      "\t0.6s = Fit runtime\n",
      "\t1 features in original data used to generate 64 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.6s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3599.4s of the 3599.39s of remaining time.\n",
      "\tNo valid features to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3599.4s of the 3599.39s of remaining time.\n",
      "\tNo valid features to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3599.39s of the 3599.39s of remaining time.\n",
      "\t0.98\t = Validation accuracy score\n",
      "\t277.27s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3321.99s of the 3321.99s of remaining time.\n",
      "\t0.978\t = Validation accuracy score\n",
      "\t308.12s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3013.77s of the 3013.77s of remaining time.\n",
      "\t0.976\t = Validation accuracy score\n",
      "\t1.03s\t = Training runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 3012.6s of the 3012.6s of remaining time.\n",
      "\t0.976\t = Validation accuracy score\n",
      "\t1.01s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3011.46s of the 3011.45s of remaining time.\n",
      "\t0.98\t = Validation accuracy score\n",
      "\t2.53s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 3008.88s of the 3008.87s of remaining time.\n",
      "\t0.976\t = Validation accuracy score\n",
      "\t1.07s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 3007.68s of the 3007.68s of remaining time.\n",
      "\t0.978\t = Validation accuracy score\n",
      "\t1.09s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3006.47s of the 3006.46s of remaining time.\n",
      "No improvement since epoch 5: early stopping\n",
      "\t0.974\t = Validation accuracy score\n",
      "\t7.05s\t = Training runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2999.13s of the 2999.12s of remaining time.\n",
      "\t0.978\t = Validation accuracy score\n",
      "\t67.69s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 2931.32s of the 2931.31s of remaining time.\n",
      "\t0.956\t = Validation accuracy score\n",
      "\t14.95s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2915.7s of the 2915.7s of remaining time.\n",
      "\t0.982\t = Validation accuracy score\n",
      "\t1011.69s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1903.88s of remaining time.\n",
      "\t0.982\t = Validation accuracy score\n",
      "\t0.5s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1696.63s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"spam_message_ms/\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      LightGBMLarge_BAG_L1      0.982       0.072572  1011.694583                0.072572        1011.694583            1       True         11\n",
      "1       WeightedEnsemble_L2      0.982       0.073705  1012.196015                0.001133           0.501431            2       True         12\n",
      "2           CatBoost_BAG_L1      0.980       0.038029     2.526551                0.038029           2.526551            1       True          5\n",
      "3         LightGBMXT_BAG_L1      0.980       0.072485   277.274959                0.072485         277.274959            1       True          1\n",
      "4           LightGBM_BAG_L1      0.978       0.069327   308.118771                0.069327         308.118771            1       True          2\n",
      "5            XGBoost_BAG_L1      0.978       0.071179    67.689072                0.071179          67.689072            1       True          9\n",
      "6     ExtraTreesEntr_BAG_L1      0.978       0.110822     1.087300                0.110822           1.087300            1       True          7\n",
      "7     ExtraTreesGini_BAG_L1      0.976       0.110946     1.065769                0.110946           1.065769            1       True          6\n",
      "8   RandomForestEntr_BAG_L1      0.976       0.111643     1.012787                0.111643           1.012787            1       True          4\n",
      "9   RandomForestGini_BAG_L1      0.976       0.118162     1.033762                0.118162           1.033762            1       True          3\n",
      "10   NeuralNetFastAI_BAG_L1      0.974       0.193666     7.050589                0.193666           7.050589            1       True          8\n",
      "11    NeuralNetMXNet_BAG_L1      0.956       0.630682    14.947454                0.630682          14.947454            1       True         10\n",
      "Number of models trained: 12\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XT', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_TabularNeuralNet', 'WeightedEnsembleModel', 'StackerEnsembleModel_XGBoost'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', ['text_as_category'])  :  1 | ['Message']\n",
      "('int', ['binned', 'text_special']) : 34 | ['Message.char_count', 'Message.word_count', 'Message.capital_ratio', 'Message.lower_ratio', 'Message.digit_ratio', ...]\n",
      "('int', ['text_ngram'])             : 29 | ['__nlp__.and', '__nlp__.are', '__nlp__.but', '__nlp__.call', '__nlp__.can', ...]\n",
      "Plot summary of models saved to file: spam_message_ms/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Inference time:\n",
    "test_data = TabularDataset('./datasets/spam-message-test.csv')  # another Pandas DataFrame\n",
    "y_test = test_data[label]\n",
    "test_data = test_data.drop(labels=[label], axis=1)  # delete labels from test data since we wouldn't have them in practice\n",
    "print(test_data.head())\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loaded data from: ./datasets/spam-message-test.csv | Columns = 2 / 2 | Rows = 1572 -> 1572\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                                                                                                                          Message\n",
      "0                                                                                                                               K...k...when will you give treat?\n",
      "1  This is the 2nd time we have tried to contact u. U have won the £400 prize. 2 claim is easy, just call 087104711148 NOW! Only 10p per minute. BT-national-rate\n",
      "2                                                                                      He's just gonna worry for nothing. And he won't give you money its no use.\n",
      "3                                                                                                    Did you get any gift? This year i didnt get anything. So bad\n",
      "4                              somewhere out there beneath the pale moon light someone think in of u some where out there where dreams come true... goodnite &amp\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "predictor = TabularPredictor.load(save_path)  # Unnecessary, we reload predictor just to demonstrate how to load previously-trained predictor from file\n",
    "y_pred = predictor.predict(test_data)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Evaluation: accuracy on test data: 0.9720101781170484\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.9720101781170484,\n",
      "    \"balanced_accuracy\": 0.9165086175626238,\n",
      "    \"mcc\": 0.8766203031349709,\n",
      "    \"f1\": 0.8905472636815921,\n",
      "    \"precision\": 0.9470899470899471,\n",
      "    \"recall\": 0.8403755868544601\n",
      "}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print('Accuracy = {:.2f}%'.format(perf[\"accuracy\"] * 100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy = 83.49%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "test_data.tail()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       0          1       2             3   4                   5  \\\n",
       "9764  30    Private  151868           9th   5  Married-civ-spouse   \n",
       "9765  32  State-gov  104509       HS-grad   9            Divorced   \n",
       "9766  22    Private  187592  Some-college  10       Never-married   \n",
       "9767  32    Private   49539  Some-college  10       Never-married   \n",
       "9768  25    Private  102476     Bachelors  13       Never-married   \n",
       "\n",
       "                    6              7      8       9     10  11  12  \\\n",
       "9764     Craft-repair        Husband  White    Male      0   0  40   \n",
       "9765    Other-service  Not-in-family  White  Female      0   0  25   \n",
       "9766  Exec-managerial  Not-in-family  White    Male      0   0  30   \n",
       "9767    Other-service  Not-in-family  White  Female   3674   0  40   \n",
       "9768  Farming-fishing      Own-child  White    Male  27828   0  50   \n",
       "\n",
       "                 13  \n",
       "9764  United-States  \n",
       "9765  United-States  \n",
       "9766  United-States  \n",
       "9767  United-States  \n",
       "9768  United-States  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9764</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>151868</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9765</th>\n",
       "      <td>32</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>104509</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>187592</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9767</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>49539</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>3674</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9768</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>102476</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>27828</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('auto_glucon': venv)"
  },
  "interpreter": {
   "hash": "8cbcbecefa271004e6582b9d6d4515a215f41598e734b38ac4197b8836b69e1c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}