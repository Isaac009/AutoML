{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\"\"\" Example script for predicting columns of tables, demonstrating simple use-case \"\"\"\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "\n",
    "# Training time:\n",
    "train_data = TabularDataset('./datasets/Corona_NLP_train.csv')  # can be local CSV file as well, returns Pandas DataFrame\n",
    "# train_data = train_data.head(500)  # subsample for faster demo\n",
    "train_data.head()\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_data.tail(100)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "40289     44852       89804                        crypto  13-04-2020   \n",
       "40290     44853       89805                 New York, USA  13-04-2020   \n",
       "40291     44854       89806                  Gulfport, MS  13-04-2020   \n",
       "40292     44855       89807    Jakarta Timur, DKI Jakarta  13-04-2020   \n",
       "40293     44856       89808                 San Diego, CA  13-04-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "40384     44950       89902                           NaN  13-04-2020   \n",
       "40385     44951       89903  Wellington City, New Zealand  13-04-2020   \n",
       "40386     44952       89904                           NaN  13-04-2020   \n",
       "40387     44953       89905                           NaN  13-04-2020   \n",
       "40388     44954       89906                           NaN  13-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "40289  China amp US Share S P Outcomes China losing w...  Extremely Positive  \n",
       "40290  Supermarket Madness! https://t.co/2oYivZtfcn\\n...            Negative  \n",
       "40291  Oil rig workers hit with one-two punch of #cor...            Negative  \n",
       "40292  Funny that one of my \"friend\" keeps on preachi...  Extremely Positive  \n",
       "40293  Grocery store workers want more protections in...            Positive  \n",
       "...                                                  ...                 ...  \n",
       "40384  @MrSilverScott you are definitely my man. I fe...  Extremely Positive  \n",
       "40385  Airline pilots offering to stock supermarket s...             Neutral  \n",
       "40386  Response to complaint not provided citing COVI...  Extremely Negative  \n",
       "40387  You know itÂ’s getting tough when @KameronWilds...            Positive  \n",
       "40388  Is it wrong that the smell of hand sanitizer i...             Neutral  \n",
       "\n",
       "[100 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40289</th>\n",
       "      <td>44852</td>\n",
       "      <td>89804</td>\n",
       "      <td>crypto</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>China amp US Share S P Outcomes China losing w...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40290</th>\n",
       "      <td>44853</td>\n",
       "      <td>89805</td>\n",
       "      <td>New York, USA</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>Supermarket Madness! https://t.co/2oYivZtfcn\\n...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40291</th>\n",
       "      <td>44854</td>\n",
       "      <td>89806</td>\n",
       "      <td>Gulfport, MS</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>Oil rig workers hit with one-two punch of #cor...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40292</th>\n",
       "      <td>44855</td>\n",
       "      <td>89807</td>\n",
       "      <td>Jakarta Timur, DKI Jakarta</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>Funny that one of my \"friend\" keeps on preachi...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40293</th>\n",
       "      <td>44856</td>\n",
       "      <td>89808</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>Grocery store workers want more protections in...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40384</th>\n",
       "      <td>44950</td>\n",
       "      <td>89902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>@MrSilverScott you are definitely my man. I fe...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40385</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40386</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40387</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>You know itÂ’s getting tough when @KameronWilds...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "label = 'Sentiment'  # specifies which column do we want to predict\n",
    "save_path = 'sentiment_analysis_covid/'  # where to save trained models"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "dl = int(40388*0.8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# splitting dataframe in a particular size\n",
    "df_split = train_data.sample(frac=1,random_state=200)\n",
    "df_split.reset_index()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     index   id              keyword              location  \\\n",
       "0      157  225  airplane%20accident     Lehigh Valley, PA   \n",
       "1       88  130             accident        Manchester, NH   \n",
       "2      383  552                arson         Charlotte, NC   \n",
       "3      125  180           aftershock                   304   \n",
       "4      445  644             arsonist                   NaN   \n",
       "..     ...  ...                  ...                   ...   \n",
       "495    298  438           apocalypse             Las Vegas   \n",
       "496    324  470           armageddon  Nowhere. Everywhere.   \n",
       "497    272  396           apocalypse              ColoRADo   \n",
       "498    105  153           aftershock                   304   \n",
       "499    282  412           apocalypse               Oakland   \n",
       "\n",
       "                                                  text  target  \n",
       "0    Strict liability in the context of an airplane...       1  \n",
       "1    Accident left lane blocked in #Manchester on R...       1  \n",
       "2                      Add Familia to the arson squad.       0  \n",
       "3    Sometimes you face difficulties not because yo...       0  \n",
       "4    Big Top Burning The True Story Of An Arsonist ...       1  \n",
       "..                                                 ...     ...  \n",
       "495  I know where to go when the zombies take over!...       0  \n",
       "496  @RohnertParkDPS You're another one for the his...       0  \n",
       "497     I'm gonna fight Taylor as soon as I get there.       0  \n",
       "498  'There is no victory at bargain basement price...       0  \n",
       "499  Julie + R is the apocalypse version of Romeo +...       0  \n",
       "\n",
       "[500 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157</td>\n",
       "      <td>225</td>\n",
       "      <td>airplane%20accident</td>\n",
       "      <td>Lehigh Valley, PA</td>\n",
       "      <td>Strict liability in the context of an airplane...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88</td>\n",
       "      <td>130</td>\n",
       "      <td>accident</td>\n",
       "      <td>Manchester, NH</td>\n",
       "      <td>Accident left lane blocked in #Manchester on R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>383</td>\n",
       "      <td>552</td>\n",
       "      <td>arson</td>\n",
       "      <td>Charlotte, NC</td>\n",
       "      <td>Add Familia to the arson squad.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>180</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>304</td>\n",
       "      <td>Sometimes you face difficulties not because yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>445</td>\n",
       "      <td>644</td>\n",
       "      <td>arsonist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Big Top Burning The True Story Of An Arsonist ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>298</td>\n",
       "      <td>438</td>\n",
       "      <td>apocalypse</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>I know where to go when the zombies take over!...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>324</td>\n",
       "      <td>470</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>Nowhere. Everywhere.</td>\n",
       "      <td>@RohnertParkDPS You're another one for the his...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>272</td>\n",
       "      <td>396</td>\n",
       "      <td>apocalypse</td>\n",
       "      <td>ColoRADo</td>\n",
       "      <td>I'm gonna fight Taylor as soon as I get there.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>105</td>\n",
       "      <td>153</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>304</td>\n",
       "      <td>'There is no victory at bargain basement price...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>282</td>\n",
       "      <td>412</td>\n",
       "      <td>apocalypse</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>Julie + R is the apocalypse version of Romeo +...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 6 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "train_data_d = train_data.iloc[:dl,]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train_data.tail()\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id      keyword location  \\\n",
       "337  484   armageddon      NaN   \n",
       "477  687       attack      NaN   \n",
       "234  334  annihilated      NaN   \n",
       "220  313  annihilated      NaN   \n",
       "382  551        arson      USA   \n",
       "\n",
       "                                                  text  target  \n",
       "337  #Christians United for #Israel (#CUFI): Jews s...       0  \n",
       "477  Heart disease prevention: What about secondhan...       0  \n",
       "234  @TomcatArts thus explaining why you were all a...       1  \n",
       "220  Cop pulls drunk driver to safety SECONDS befor...       1  \n",
       "382  Thousands attend a rally organized by Peace No...       1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>484</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Christians United for #Israel (#CUFI): Jews s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>687</td>\n",
       "      <td>attack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heart disease prevention: What about secondhan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>334</td>\n",
       "      <td>annihilated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@TomcatArts thus explaining why you were all a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>313</td>\n",
       "      <td>annihilated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cop pulls drunk driver to safety SECONDS befor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>551</td>\n",
       "      <td>arson</td>\n",
       "      <td>USA</td>\n",
       "      <td>Thousands attend a rally organized by Peace No...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "test_data = train_data.iloc[dl:,]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "test_data.tail()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id     keyword              location  \\\n",
       "298  438  apocalypse             Las Vegas   \n",
       "324  470  armageddon  Nowhere. Everywhere.   \n",
       "272  396  apocalypse              ColoRADo   \n",
       "105  153  aftershock                   304   \n",
       "282  412  apocalypse               Oakland   \n",
       "\n",
       "                                                  text  target  \n",
       "298  I know where to go when the zombies take over!...       0  \n",
       "324  @RohnertParkDPS You're another one for the his...       0  \n",
       "272     I'm gonna fight Taylor as soon as I get there.       0  \n",
       "105  'There is no victory at bargain basement price...       0  \n",
       "282  Julie + R is the apocalypse version of Romeo +...       0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>438</td>\n",
       "      <td>apocalypse</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>I know where to go when the zombies take over!...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>470</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>Nowhere. Everywhere.</td>\n",
       "      <td>@RohnertParkDPS You're another one for the his...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>396</td>\n",
       "      <td>apocalypse</td>\n",
       "      <td>ColoRADo</td>\n",
       "      <td>I'm gonna fight Taylor as soon as I get there.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>153</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>304</td>\n",
       "      <td>'There is no victory at bargain basement price...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>412</td>\n",
       "      <td>apocalypse</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>Julie + R is the apocalypse version of Romeo +...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "predictor = TabularPredictor(label=label, path=save_path).fit(train_data, time_limit=3600, presets='best_quality')\n",
    "# NOTE: Default settings above are intended to ensure reasonable runtime at the cost of accuracy. To maximize predictive accuracy, do this instead:\n",
    "# predictor = TabularPredictor(label=label, eval_metric=YOUR_METRIC_NAME, path=save_path).fit(train_data, presets='best_quality')\n",
    "results = predictor.fit_summary()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"sentiment_analysis_covid/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    40389\n",
      "Train Data Columns: 5\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t6 unique label values:  ['Neutral', 'Positive', 'Extremely Negative', 'Negative', 'Extremely Positive', 'w']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 5 out of 6 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9999752407833816\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    481273.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['OriginalTweet']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 7818\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])                        : 2 | ['UserName', 'ScreenName']\n",
      "\t\t('object', [])                     : 1 | ['Location']\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['TweetAt']\n",
      "\t\t('object', ['text'])               : 1 | ['OriginalTweet']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    1 | ['Location']\n",
      "\t\t('int', [])                         :    2 | ['UserName', 'ScreenName']\n",
      "\t\t('int', ['binned', 'text_special']) :   38 | ['OriginalTweet.char_count', 'OriginalTweet.word_count', 'OriginalTweet.capital_ratio', 'OriginalTweet.lower_ratio', 'OriginalTweet.digit_ratio', ...]\n",
      "\t\t('int', ['datetime_as_int'])        :    1 | ['TweetAt']\n",
      "\t\t('int', ['text_ngram'])             : 7819 | ['__nlp__.00', '__nlp__.000', '__nlp__.000 to', '__nlp__.10', '__nlp__.10 000', ...]\n",
      "\t38.3s = Fit runtime\n",
      "\t5 features in original data used to generate 7861 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 318.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 39.61s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2372.98s of the 3560.08s of remaining time.\n",
      "\t0.2178\t = Validation accuracy score\n",
      "\t3.8s\t = Training runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2368.37s of the 3555.47s of remaining time.\n",
      "\t0.2252\t = Validation accuracy score\n",
      "\t3.79s\t = Training runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2363.72s of the 3550.82s of remaining time.\n",
      "\tRan out of time, stopping training early.\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1833.3s of the 3020.4s of remaining time.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1000]\ttrain_set's multi_error: 0.0869876\tvalid_set's multi_error: 0.345468\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\t0.6452\t = Validation accuracy score\n",
      "\t335.49s\t = Training runtime\n",
      "\t5.55s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1490.47s of the 2677.57s of remaining time.\n",
      "\t0.635\t = Validation accuracy score\n",
      "\t362.4s\t = Training runtime\n",
      "\t5.49s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1120.57s of the 2307.67s of remaining time.\n",
      "\t0.4789\t = Validation accuracy score\n",
      "\t39.93s\t = Training runtime\n",
      "\t152.14s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 926.22s of the 2113.32s of remaining time.\n",
      "\t0.4729\t = Validation accuracy score\n",
      "\t36.17s\t = Training runtime\n",
      "\t153.84s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 733.59s of the 1920.69s of remaining time.\n",
      "\tMany features detected (7861), dynamically setting 'colsample_bylevel' to 0.12721027859051012 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (7861), dynamically setting 'colsample_bylevel' to 0.12721027859051012 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (7861), dynamically setting 'colsample_bylevel' to 0.12721027859051012 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (7861), dynamically setting 'colsample_bylevel' to 0.12721027859051012 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (7861), dynamically setting 'colsample_bylevel' to 0.12721027859051012 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (7861), dynamically setting 'colsample_bylevel' to 0.12721027859051012 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (7861), dynamically setting 'colsample_bylevel' to 0.12721027859051012 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (7861), dynamically setting 'colsample_bylevel' to 0.12721027859051012 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (7861), dynamically setting 'colsample_bylevel' to 0.12721027859051012 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (7861), dynamically setting 'colsample_bylevel' to 0.12721027859051012 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\t0.5634\t = Validation accuracy score\n",
      "\t427.81s\t = Training runtime\n",
      "\t6.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 298.76s of the 1485.85s of remaining time.\n",
      "\t0.5033\t = Validation accuracy score\n",
      "\t49.47s\t = Training runtime\n",
      "\t164.88s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 81.75s of the 1268.85s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 146 due to low time. Expected time usage reduced from 161.4s -> 81.7s...\n",
      "\t0.4816\t = Validation accuracy score\n",
      "\t27.13s\t = Training runtime\n",
      "\t83.28s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.97s of the 1156.45s of remaining time.\n",
      "\t0.6452\t = Validation accuracy score\n",
      "\t5.73s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsUnif_BAG_L2 ... Training model for up to 1150.29s of the 1149.9s of remaining time.\n",
      "\t0.2375\t = Validation accuracy score\n",
      "\t1.67s\t = Training runtime\n",
      "\t48.47s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L2 ... Training model for up to 1098.61s of the 1098.22s of remaining time.\n",
      "\t0.2743\t = Validation accuracy score\n",
      "\t1.63s\t = Training runtime\n",
      "\t48.62s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1047.07s of the 1046.68s of remaining time.\n",
      "\tRan out of time, stopping training early.\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 687.92s of the 687.52s of remaining time.\n",
      "\t0.7006\t = Validation accuracy score\n",
      "\t147.17s\t = Training runtime\n",
      "\t3.36s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 536.66s of the 536.26s of remaining time.\n",
      "\t0.6992\t = Validation accuracy score\n",
      "\t135.18s\t = Training runtime\n",
      "\t3.3s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 397.54s of the 397.15s of remaining time.\n",
      "\t0.6818\t = Validation accuracy score\n",
      "\t26.75s\t = Training runtime\n",
      "\t158.21s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 210.67s of the 210.28s of remaining time.\n",
      "\t0.6804\t = Validation accuracy score\n",
      "\t23.96s\t = Training runtime\n",
      "\t157.21s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 27.35s of the 26.96s of remaining time.\n",
      "\tMany features detected (7906), dynamically setting 'colsample_bylevel' to 0.1264862130027827 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tTime limit exceeded... Skipping CatBoost_BAG_L2.\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 22.7s of the 22.31s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 42 due to low time. Expected time usage reduced from 130.6s -> 22.7s...\n",
      "\t0.6536\t = Validation accuracy score\n",
      "\t12.54s\t = Training runtime\n",
      "\t23.0s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.98s of the -14.3s of remaining time.\n",
      "\t0.7007\t = Validation accuracy score\n",
      "\t4.61s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3620.0s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"sentiment_analysis_covid/\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L3   0.700654     578.414408  1572.945642                0.004621           4.609092            3       True         18\n",
      "1         LightGBMXT_BAG_L2   0.700579     575.105938  1433.159260                3.364214         147.165360            2       True         13\n",
      "2           LightGBM_BAG_L2   0.699193     575.045573  1421.171190                3.303849         135.177290            2       True         14\n",
      "3   RandomForestGini_BAG_L2   0.681811     729.951479  1312.743960              158.209755          26.750060            2       True         15\n",
      "4   RandomForestEntr_BAG_L2   0.680450     728.952668  1309.958629              157.210944          23.964729            2       True         16\n",
      "5     ExtraTreesGini_BAG_L2   0.653585     594.737478  1298.532691               22.995754          12.538791            2       True         17\n",
      "6         LightGBMXT_BAG_L1   0.645241       5.554108   335.493617                5.554108         335.493617            1       True          3\n",
      "7       WeightedEnsemble_L2   0.645241       5.558839   341.227272                0.004730           5.733654            2       True         10\n",
      "8           LightGBM_BAG_L1   0.635040       5.486069   362.395304                5.486069         362.395304            1       True          4\n",
      "9           CatBoost_BAG_L1   0.563360       6.102297   427.810738                6.102297         427.810738            1       True          7\n",
      "10    ExtraTreesGini_BAG_L1   0.503268     164.875634    49.467565              164.875634          49.467565            1       True          8\n",
      "11    ExtraTreesEntr_BAG_L1   0.481603      83.277468    27.131990               83.277468          27.131990            1       True          9\n",
      "12  RandomForestGini_BAG_L1   0.478855     152.144330    39.928421              152.144330          39.928421            1       True          5\n",
      "13  RandomForestEntr_BAG_L1   0.472863     153.844460    36.172904              153.844460          36.172904            1       True          6\n",
      "14    KNeighborsDist_BAG_L2   0.274339     620.361601  1287.620634               48.619876           1.626734            2       True         12\n",
      "15    KNeighborsUnif_BAG_L2   0.237521     620.209434  1287.664135               48.467710           1.670235            2       True         11\n",
      "16    KNeighborsDist_BAG_L1   0.225191       0.229935     3.793041                0.229935           3.793041            1       True          2\n",
      "17    KNeighborsUnif_BAG_L1   0.217812       0.227422     3.800319                0.227422           3.800319            1       True          1\n",
      "Number of models trained: 18\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_KNN', 'StackerEnsembleModel_XT', 'WeightedEnsembleModel', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_CatBoost'}\n",
      "Bagging used: True  (with 10 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])                    :    1 | ['Location']\n",
      "('int', [])                         :    2 | ['UserName', 'ScreenName']\n",
      "('int', ['binned', 'text_special']) :   38 | ['OriginalTweet.char_count', 'OriginalTweet.word_count', 'OriginalTweet.capital_ratio', 'OriginalTweet.lower_ratio', 'OriginalTweet.digit_ratio', ...]\n",
      "('int', ['datetime_as_int'])        :    1 | ['TweetAt']\n",
      "('int', ['text_ngram'])             : 7819 | ['__nlp__.00', '__nlp__.000', '__nlp__.000 to', '__nlp__.10', '__nlp__.10 000', ...]\n",
      "Plot summary of models saved to file: sentiment_analysis_covid/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Inference time:\n",
    "# test_data = TabularDataset('./datasets/nlp-getting-started/test.csv')  # another Pandas DataFrame\n",
    "y_test = test_data[label]\n",
    "test_data = test_data.drop(labels=[label], axis=1)  # delete labels from test data since we wouldn't have them in practice\n",
    "print(test_data.head())\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       UserName  ScreenName      Location     TweetAt  \\\n",
      "32310     36745       81697        Global  07-04-2020   \n",
      "32311     36746       81698       Chicago  07-04-2020   \n",
      "32312     36747       81699  Florida, USA  07-04-2020   \n",
      "32313     36748       81700           NaN  07-04-2020   \n",
      "32314     36749       81701           NaN  07-04-2020   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                              OriginalTweet  \n",
      "32310                                              I've been window shopping on online grocery delivery sites. Am I alone in my madness? What are you guys doing?\\n\\n\\n\\n#covid19 #covid #coronavirus #coronavirusindia #lockdown #lockdowneffect #lockdown21 #LockdownDiaries #lockdownindia #lockdowndelhi #lockedindelhi  \n",
      "32311  Private equity funds arenÂ’t just seeking to save the investments they already have, but to get access to more capital to invest in a period where asset prices are quite low. \\n\\n\\n\\nRead more from @matthewstoller on companies lobbying to profit from #COVID19 : https://t.co/tvGxFitfEe https://t.co/nGTzxCGago  \n",
      "32312                                                                                                                                                                                                   Food shopping may be as dangerous as voting in the It s confirmed at least 4 grocery store employees have died from  \n",
      "32313                                                                             People at the grocery store are threatening to go to blows over #SocialDistancing.\\n\\n\\n\\nMy wife asked a man if he was in line, he replied yes, then asked her to give him six feet of space. While he said please, he was being a dick.  \n",
      "32314                                                                                                     Promano Liquid Hand Sanitizer kills 99.99% of bacteria and removes viruses without the need of water nor soap.\\n\\n#COVID19 #germs #bacteria #viruses #coronavirus #handsanitizer #promano https://t.co/L1EHvGS92p  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "predictor = TabularPredictor.load(save_path)  # Unnecessary, we reload predictor just to demonstrate how to load previously-trained predictor from file\n",
    "y_pred = predictor.predict(test_data)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Evaluation: accuracy on test data: 0.9200396088624829\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.9200396088624829,\n",
      "    \"balanced_accuracy\": 0.9088930852341104,\n",
      "    \"mcc\": 0.8981982317625083\n",
      "}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print('Accuracy = {:.2f}%'.format(perf[\"accuracy\"] * 100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy = 92.00%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "test_data.tail()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "40384     44950       89902                           NaN  13-04-2020   \n",
       "40385     44951       89903  Wellington City, New Zealand  13-04-2020   \n",
       "40386     44952       89904                           NaN  13-04-2020   \n",
       "40387     44953       89905                           NaN  13-04-2020   \n",
       "40388     44954       89906                           NaN  13-04-2020   \n",
       "\n",
       "                                                                                                                                                                                                                                                        OriginalTweet  \n",
       "40384  @MrSilverScott you are definitely my man. I feel like this fall when we are out and about again, we need to honor our heroes from COVID-19. You know who they are Â— our healthcare people , grocery store owners, and anyone else putting their life on the li  \n",
       "40385                                                                                                                                                          Airline pilots offering to stock supermarket shelves in #NZ lockdown #COVID-19 https://t.co/cz89uA0HNp  \n",
       "40386                                                                                                                      Response to complaint not provided citing COVID-19 related delays. Yet prompt in rejecting policy before consumer TAT is over. Way to go ?  \n",
       "40387                                                                                                                         You know itÂ’s getting tough when @KameronWilds  is rationing toilet paper #coronavirus #toiletpaper @kroger martinsville, help us out!!  \n",
       "40388                                                                                                                                               Is it wrong that the smell of hand sanitizer is starting to turn me on?\\n\\n\\n\\n#coronavirus #COVID19 #coronavirus  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40384</th>\n",
       "      <td>44950</td>\n",
       "      <td>89902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>@MrSilverScott you are definitely my man. I feel like this fall when we are out and about again, we need to honor our heroes from COVID-19. You know who they are Â— our healthcare people , grocery store owners, and anyone else putting their life on the li</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40385</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>Airline pilots offering to stock supermarket shelves in #NZ lockdown #COVID-19 https://t.co/cz89uA0HNp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40386</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>Response to complaint not provided citing COVID-19 related delays. Yet prompt in rejecting policy before consumer TAT is over. Way to go ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40387</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>You know itÂ’s getting tough when @KameronWilds  is rationing toilet paper #coronavirus #toiletpaper @kroger martinsville, help us out!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer is starting to turn me on?\\n\\n\\n\\n#coronavirus #COVID19 #coronavirus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('auto_glucon': venv)"
  },
  "interpreter": {
   "hash": "8cbcbecefa271004e6582b9d6d4515a215f41598e734b38ac4197b8836b69e1c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}