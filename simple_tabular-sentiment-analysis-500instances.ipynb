{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\"\"\" Example script for predicting columns of tables, demonstrating simple use-case \"\"\"\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "\n",
    "# Training time:\n",
    "train_data = TabularDataset('./datasets/nlp-getting-started/train.csv')  # can be local CSV file as well, returns Pandas DataFrame\n",
    "train_data = train_data.head(500)  # subsample for faster demo\n",
    "print(train_data.head())\n",
    "label = 'target'  # specifies which column do we want to predict\n",
    "save_path = 'sentiment_analysis/'  # where to save trained models\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   id keyword location                                               text  \\\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
      "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
      "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
      "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
      "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# splitting dataframe in a particular size\n",
    "df_split = train_data.sample(frac=1,random_state=200)\n",
    "df_split.reset_index()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     index   id              keyword              location  \\\n",
       "0      157  225  airplane%20accident     Lehigh Valley, PA   \n",
       "1       88  130             accident        Manchester, NH   \n",
       "2      383  552                arson         Charlotte, NC   \n",
       "3      125  180           aftershock                   304   \n",
       "4      445  644             arsonist                   NaN   \n",
       "..     ...  ...                  ...                   ...   \n",
       "495    298  438           apocalypse             Las Vegas   \n",
       "496    324  470           armageddon  Nowhere. Everywhere.   \n",
       "497    272  396           apocalypse              ColoRADo   \n",
       "498    105  153           aftershock                   304   \n",
       "499    282  412           apocalypse               Oakland   \n",
       "\n",
       "                                                  text  target  \n",
       "0    Strict liability in the context of an airplane...       1  \n",
       "1    Accident left lane blocked in #Manchester on R...       1  \n",
       "2                      Add Familia to the arson squad.       0  \n",
       "3    Sometimes you face difficulties not because yo...       0  \n",
       "4    Big Top Burning The True Story Of An Arsonist ...       1  \n",
       "..                                                 ...     ...  \n",
       "495  I know where to go when the zombies take over!...       0  \n",
       "496  @RohnertParkDPS You're another one for the his...       0  \n",
       "497     I'm gonna fight Taylor as soon as I get there.       0  \n",
       "498  'There is no victory at bargain basement price...       0  \n",
       "499  Julie + R is the apocalypse version of Romeo +...       0  \n",
       "\n",
       "[500 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157</td>\n",
       "      <td>225</td>\n",
       "      <td>airplane%20accident</td>\n",
       "      <td>Lehigh Valley, PA</td>\n",
       "      <td>Strict liability in the context of an airplane...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88</td>\n",
       "      <td>130</td>\n",
       "      <td>accident</td>\n",
       "      <td>Manchester, NH</td>\n",
       "      <td>Accident left lane blocked in #Manchester on R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>383</td>\n",
       "      <td>552</td>\n",
       "      <td>arson</td>\n",
       "      <td>Charlotte, NC</td>\n",
       "      <td>Add Familia to the arson squad.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>180</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>304</td>\n",
       "      <td>Sometimes you face difficulties not because yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>445</td>\n",
       "      <td>644</td>\n",
       "      <td>arsonist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Big Top Burning The True Story Of An Arsonist ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>298</td>\n",
       "      <td>438</td>\n",
       "      <td>apocalypse</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>I know where to go when the zombies take over!...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>324</td>\n",
       "      <td>470</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>Nowhere. Everywhere.</td>\n",
       "      <td>@RohnertParkDPS You're another one for the his...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>272</td>\n",
       "      <td>396</td>\n",
       "      <td>apocalypse</td>\n",
       "      <td>ColoRADo</td>\n",
       "      <td>I'm gonna fight Taylor as soon as I get there.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>105</td>\n",
       "      <td>153</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>304</td>\n",
       "      <td>'There is no victory at bargain basement price...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>282</td>\n",
       "      <td>412</td>\n",
       "      <td>apocalypse</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>Julie + R is the apocalypse version of Romeo +...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 6 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_data = df_split.iloc[:400,]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train_data.tail()\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id      keyword location  \\\n",
       "337  484   armageddon      NaN   \n",
       "477  687       attack      NaN   \n",
       "234  334  annihilated      NaN   \n",
       "220  313  annihilated      NaN   \n",
       "382  551        arson      USA   \n",
       "\n",
       "                                                  text  target  \n",
       "337  #Christians United for #Israel (#CUFI): Jews s...       0  \n",
       "477  Heart disease prevention: What about secondhan...       0  \n",
       "234  @TomcatArts thus explaining why you were all a...       1  \n",
       "220  Cop pulls drunk driver to safety SECONDS befor...       1  \n",
       "382  Thousands attend a rally organized by Peace No...       1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>484</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Christians United for #Israel (#CUFI): Jews s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>687</td>\n",
       "      <td>attack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heart disease prevention: What about secondhan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>334</td>\n",
       "      <td>annihilated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@TomcatArts thus explaining why you were all a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>313</td>\n",
       "      <td>annihilated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cop pulls drunk driver to safety SECONDS befor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>551</td>\n",
       "      <td>arson</td>\n",
       "      <td>USA</td>\n",
       "      <td>Thousands attend a rally organized by Peace No...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "test_data = df_split.iloc[400:,]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "test_data.tail()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id     keyword              location  \\\n",
       "298  438  apocalypse             Las Vegas   \n",
       "324  470  armageddon  Nowhere. Everywhere.   \n",
       "272  396  apocalypse              ColoRADo   \n",
       "105  153  aftershock                   304   \n",
       "282  412  apocalypse               Oakland   \n",
       "\n",
       "                                                  text  target  \n",
       "298  I know where to go when the zombies take over!...       0  \n",
       "324  @RohnertParkDPS You're another one for the his...       0  \n",
       "272     I'm gonna fight Taylor as soon as I get there.       0  \n",
       "105  'There is no victory at bargain basement price...       0  \n",
       "282  Julie + R is the apocalypse version of Romeo +...       0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>438</td>\n",
       "      <td>apocalypse</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>I know where to go when the zombies take over!...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>470</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>Nowhere. Everywhere.</td>\n",
       "      <td>@RohnertParkDPS You're another one for the his...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>396</td>\n",
       "      <td>apocalypse</td>\n",
       "      <td>ColoRADo</td>\n",
       "      <td>I'm gonna fight Taylor as soon as I get there.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>153</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>304</td>\n",
       "      <td>'There is no victory at bargain basement price...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>412</td>\n",
       "      <td>apocalypse</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>Julie + R is the apocalypse version of Romeo +...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "predictor = TabularPredictor(label=label, path=save_path).fit(train_data, time_limit=3600, presets='best_quality')\n",
    "# NOTE: Default settings above are intended to ensure reasonable runtime at the cost of accuracy. To maximize predictive accuracy, do this instead:\n",
    "# predictor = TabularPredictor(label=label, eval_metric=YOUR_METRIC_NAME, path=save_path).fit(train_data, presets='best_quality')\n",
    "results = predictor.fit_summary()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"sentiment_analysis/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    400\n",
      "Train Data Columns: 4\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    491054.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.12 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['text']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 21\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 1 | ['id']\n",
      "\t\t('object', [])       : 2 | ['keyword', 'location']\n",
      "\t\t('object', ['text']) : 1 | ['text']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  2 | ['keyword', 'location']\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['text']\n",
      "\t\t('int', [])                         :  1 | ['id']\n",
      "\t\t('int', ['binned', 'text_special']) : 31 | ['text.char_count', 'text.word_count', 'text.capital_ratio', 'text.lower_ratio', 'text.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 22 | ['__nlp__.accident', '__nlp__.an', '__nlp__.and', '__nlp__.armageddon', '__nlp__.attack', ...]\n",
      "\t0.6s = Fit runtime\n",
      "\t4 features in original data used to generate 57 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.61s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3599.38s of the 3599.38s of remaining time.\n",
      "\t0.6575\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3599.25s of the 3599.25s of remaining time.\n",
      "\t0.675\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3599.12s of the 3599.11s of remaining time.\n",
      "\t0.78\t = Validation accuracy score\n",
      "\t207.47s\t = Training runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3391.52s of the 3391.52s of remaining time.\n",
      "\t0.7675\t = Validation accuracy score\n",
      "\t189.34s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3202.07s of the 3202.07s of remaining time.\n",
      "\t0.75\t = Validation accuracy score\n",
      "\t1.09s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 3200.85s of the 3200.84s of remaining time.\n",
      "\t0.735\t = Validation accuracy score\n",
      "\t1.1s\t = Training runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3199.61s of the 3199.6s of remaining time.\n",
      "\t0.82\t = Validation accuracy score\n",
      "\t4.86s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 3194.68s of the 3194.68s of remaining time.\n",
      "\t0.7175\t = Validation accuracy score\n",
      "\t1.07s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 3193.47s of the 3193.47s of remaining time.\n",
      "\t0.725\t = Validation accuracy score\n",
      "\t1.08s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3192.25s of the 3192.24s of remaining time.\n",
      "No improvement since epoch 3: early stopping\n",
      "\t0.7625\t = Validation accuracy score\n",
      "\t7.11s\t = Training runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3184.85s of the 3184.84s of remaining time.\n",
      "\t0.7475\t = Validation accuracy score\n",
      "\t132.83s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 3051.86s of the 3051.85s of remaining time.\n",
      "\t0.7125\t = Validation accuracy score\n",
      "\t18.94s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3032.25s of the 3032.24s of remaining time.\n",
      "\t0.765\t = Validation accuracy score\n",
      "\t765.24s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Repeating k-fold bagging: 2/20\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2266.89s of the 2266.89s of remaining time.\n",
      "\t0.6575\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2266.89s of the 2266.88s of remaining time.\n",
      "\t0.675\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2266.88s of the 2266.88s of remaining time.\n",
      "\t0.765\t = Validation accuracy score\n",
      "\t392.63s\t = Training runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2081.6s of the 2081.59s of remaining time.\n",
      "\t0.76\t = Validation accuracy score\n",
      "\t368.99s\t = Training runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1901.83s of the 1901.83s of remaining time.\n",
      "\t0.75\t = Validation accuracy score\n",
      "\t1.09s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1901.83s of the 1901.82s of remaining time.\n",
      "\t0.735\t = Validation accuracy score\n",
      "\t1.1s\t = Training runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1901.83s of the 1901.82s of remaining time.\n",
      "\t0.805\t = Validation accuracy score\n",
      "\t9.33s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1897.29s of the 1897.28s of remaining time.\n",
      "\t0.7175\t = Validation accuracy score\n",
      "\t1.07s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1897.28s of the 1897.28s of remaining time.\n",
      "\t0.725\t = Validation accuracy score\n",
      "\t1.08s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1897.28s of the 1897.27s of remaining time.\n",
      "No improvement since epoch 8: early stopping\n",
      "No improvement since epoch 6: early stopping\n",
      "No improvement since epoch 8: early stopping\n",
      "No improvement since epoch 5: early stopping\n",
      "\t0.75\t = Validation accuracy score\n",
      "\t10.8s\t = Training runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1893.31s of the 1893.3s of remaining time.\n",
      "\t0.7325\t = Validation accuracy score\n",
      "\t139.19s\t = Training runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 1886.85s of the 1886.84s of remaining time.\n",
      "\t0.715\t = Validation accuracy score\n",
      "\t50.87s\t = Training runtime\n",
      "\t1.48s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1854.05s of the 1854.04s of remaining time.\n",
      "\t0.7725\t = Validation accuracy score\n",
      "\t1586.48s\t = Training runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Completed 2/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1032.67s of remaining time.\n",
      "\t0.8075\t = Validation accuracy score\n",
      "\t0.58s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2567.93s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"sentiment_analysis/\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L2     0.8075       0.214711     9.916116                0.001120           0.581162            2       True         14\n",
      "1           CatBoost_BAG_L1     0.8050       0.097949     9.329972                0.097949           9.329972            1       True          7\n",
      "2      LightGBMLarge_BAG_L1     0.7725       0.166701  1586.481089                0.166701        1586.481089            1       True         13\n",
      "3         LightGBMXT_BAG_L1     0.7650       0.170517   392.634122                0.170517         392.634122            1       True          3\n",
      "4           LightGBM_BAG_L1     0.7600       0.160803   368.991084                0.160803         368.991084            1       True          4\n",
      "5   RandomForestGini_BAG_L1     0.7500       0.114062     1.089460                0.114062           1.089460            1       True          5\n",
      "6    NeuralNetFastAI_BAG_L1     0.7500       0.387781    10.804144                0.387781          10.804144            1       True         10\n",
      "7   RandomForestEntr_BAG_L1     0.7350       0.116587     1.097111                0.116587           1.097111            1       True          6\n",
      "8            XGBoost_BAG_L1     0.7325       0.122570   139.188960                0.122570         139.188960            1       True         11\n",
      "9     ExtraTreesEntr_BAG_L1     0.7250       0.114854     1.084907                0.114854           1.084907            1       True          9\n",
      "10    ExtraTreesGini_BAG_L1     0.7175       0.111541     1.072133                0.111541           1.072133            1       True          8\n",
      "11    NeuralNetMXNet_BAG_L1     0.7150       1.476099    50.867571                1.476099          50.867571            1       True         12\n",
      "12    KNeighborsDist_BAG_L1     0.6750       0.113259     0.003663                0.113259           0.003663            1       True          2\n",
      "13    KNeighborsUnif_BAG_L1     0.6575       0.115642     0.004982                0.115642           0.004982            1       True          1\n",
      "Number of models trained: 14\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_RF', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_NNFastAiTabular', 'WeightedEnsembleModel', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_TabularNeuralNet', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_CatBoost'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])                    :  2 | ['keyword', 'location']\n",
      "('category', ['text_as_category'])  :  1 | ['text']\n",
      "('int', [])                         :  1 | ['id']\n",
      "('int', ['binned', 'text_special']) : 31 | ['text.char_count', 'text.word_count', 'text.capital_ratio', 'text.lower_ratio', 'text.digit_ratio', ...]\n",
      "('int', ['text_ngram'])             : 22 | ['__nlp__.accident', '__nlp__.an', '__nlp__.and', '__nlp__.armageddon', '__nlp__.attack', ...]\n",
      "Plot summary of models saved to file: sentiment_analysis/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Inference time:\n",
    "# test_data = TabularDataset('./datasets/nlp-getting-started/test.csv')  # another Pandas DataFrame\n",
    "y_test = test_data[label]\n",
    "test_data = test_data.drop(labels=[label], axis=1)  # delete labels from test data since we wouldn't have them in practice\n",
    "print(test_data.head())\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      id              keyword              location  \\\n",
      "155  221  airplane%20accident    Not a U.S resident   \n",
      "293  429           apocalypse         Harlingen, TX   \n",
      "38    56               ablaze                   NaN   \n",
      "82   119             accident                   NaN   \n",
      "173  248            ambulance  New York / Worldwide   \n",
      "\n",
      "                                                                                                                                             text  \n",
      "155                                                                        Usama bin Ladins family dead in airplane crash. Naturally no accident.  \n",
      "293                                                            My niece just asked me 'would you be scared if there was an apocalypse here?' ????  \n",
      "38   Barbados #Bridgetown JAMAICA Â‰Ã›Ã’ Two cars set ablaze: SANTA CRUZ Â‰Ã›Ã“ Head of the St Elizabeth Police Superintende...  http://t.co/wDUEaj8Q4J  \n",
      "82                                                               Can wait to see how pissed Donnie is when I tell him I was in ANOTHER accident??  \n",
      "173    Two air ambulances on scene of serious crash between two cars and lorry in ... - http://t.co/9pFEaQeSki http://t.co/fntG70rnkx | #EMSNeÂ‰Ã›_  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "predictor = TabularPredictor.load(save_path)  # Unnecessary, we reload predictor just to demonstrate how to load previously-trained predictor from file\n",
    "y_pred = predictor.predict(test_data)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Evaluation: accuracy on test data: 0.81\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.81,\n",
      "    \"balanced_accuracy\": 0.8087113608992373,\n",
      "    \"mcc\": 0.6182920693179746,\n",
      "    \"f1\": 0.795698924731183,\n",
      "    \"precision\": 0.8043478260869565,\n",
      "    \"recall\": 0.7872340425531915\n",
      "}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print('Accuracy = {:.2f}%'.format(perf[\"accuracy\"] * 100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy = 83.49%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "test_data.tail()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       0          1       2             3   4                   5  \\\n",
       "9764  30    Private  151868           9th   5  Married-civ-spouse   \n",
       "9765  32  State-gov  104509       HS-grad   9            Divorced   \n",
       "9766  22    Private  187592  Some-college  10       Never-married   \n",
       "9767  32    Private   49539  Some-college  10       Never-married   \n",
       "9768  25    Private  102476     Bachelors  13       Never-married   \n",
       "\n",
       "                    6              7      8       9     10  11  12  \\\n",
       "9764     Craft-repair        Husband  White    Male      0   0  40   \n",
       "9765    Other-service  Not-in-family  White  Female      0   0  25   \n",
       "9766  Exec-managerial  Not-in-family  White    Male      0   0  30   \n",
       "9767    Other-service  Not-in-family  White  Female   3674   0  40   \n",
       "9768  Farming-fishing      Own-child  White    Male  27828   0  50   \n",
       "\n",
       "                 13  \n",
       "9764  United-States  \n",
       "9765  United-States  \n",
       "9766  United-States  \n",
       "9767  United-States  \n",
       "9768  United-States  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9764</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>151868</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9765</th>\n",
       "      <td>32</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>104509</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>187592</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9767</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>49539</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>3674</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9768</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>102476</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>27828</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('auto_glucon': venv)"
  },
  "interpreter": {
   "hash": "8cbcbecefa271004e6582b9d6d4515a215f41598e734b38ac4197b8836b69e1c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}