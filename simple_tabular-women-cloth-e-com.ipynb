{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\"\"\" Example script for predicting columns of tables, demonstrating simple use-case \"\"\"\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "\n",
    "# Training time:\n",
    "train_data = TabularDataset('./datasets/Womens-clothing-E-CommerceReviews-train.csv')  # can be local CSV file as well, returns Pandas DataFrame\n",
    "train_data = train_data.head(500)  # subsample for faster demo\n",
    "print(train_data.head())\n",
    "label = 'class'  # specifies which column do we want to predict\n",
    "save_path = 'adult_bsq_ms/'  # where to save trained models\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Clothing ID  Age                    Title  \\\n",
      "0          767   33                      NaN   \n",
      "1         1080   34                      NaN   \n",
      "2         1077   60  Some major design flaws   \n",
      "3         1049   50         My favorite buy!   \n",
      "4          847   47         Flattering shirt   \n",
      "\n",
      "                                         Review Text Rating Recommended IND  \\\n",
      "0  Absolutely wonderful - silky and sexy and comf...      4               1   \n",
      "1  Love this dress!  it's sooo pretty.  i happene...      5               1   \n",
      "2  I had such high hopes for this dress and reall...      3               0   \n",
      "3  I love, love, love this jumpsuit. it's fun, fl...      5               1   \n",
      "4  This shirt is very flattering to all due to th...      5               1   \n",
      "\n",
      "  Positive Feedback Count   Division Name Department Name      class  \n",
      "0                       0       Initmates        Intimate  Intimates  \n",
      "1                       4         General         Dresses    Dresses  \n",
      "2                       0         General         Dresses    Dresses  \n",
      "3                       0  General Petite         Bottoms      Pants  \n",
      "4                       6         General            Tops    Blouses  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "predictor = TabularPredictor(label=label, path=save_path).fit(train_data, time_limit=3600, presets='best_quality')\n",
    "# NOTE: Default settings above are intended to ensure reasonable runtime at the cost of accuracy. To maximize predictive accuracy, do this instead:\n",
    "# predictor = TabularPredictor(label=label, eval_metric=YOUR_METRIC_NAME, path=save_path).fit(train_data, presets='best_quality')\n",
    "results = predictor.fit_summary()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"adult_bsq_ms/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"adult_bsq_ms/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 9\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 18) unique label values:  ['Intimates', 'Dresses', 'Pants', 'Blouses', 'Knits', 'Outerwear', 'Lounge', 'Sweaters', 'Skirts', 'Fine gauge']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Updated label_count_threshold from 10 to 4 to avoid cutting too many classes.\n",
      "Warning: Updated num_bag_folds from 5 to 4 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 4 examples. AutoGluon will only keep 13 out of 18 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 4 examples that will be kept for training models: 0.982\n",
      "Train Data Class Count: 13\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    492244.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.37 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Title', 'Review Text', 'Rating']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 181\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 2 | ['Clothing ID', 'Age']\n",
      "\t\t('object', [])       : 4 | ['Recommended IND', 'Positive Feedback Count', 'Division Name', 'Department Name']\n",
      "\t\t('object', ['text']) : 3 | ['Title', 'Review Text', 'Rating']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   4 | ['Recommended IND', 'Positive Feedback Count', 'Division Name', 'Department Name']\n",
      "\t\t('category', ['text_as_category'])  :   3 | ['Title', 'Review Text', 'Rating']\n",
      "\t\t('int', [])                         :   2 | ['Clothing ID', 'Age']\n",
      "\t\t('int', ['binned', 'text_special']) :  52 | ['Title.char_count', 'Title.word_count', 'Title.capital_ratio', 'Title.lower_ratio', 'Title.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 182 | ['__nlp__.about', '__nlp__.all', '__nlp__.also', '__nlp__.am', '__nlp__.an', ...]\n",
      "\t1.8s = Fit runtime\n",
      "\t9 features in original data used to generate 243 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.14 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.9s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3598.1s of the 3598.08s of remaining time.\n",
      "\t0.9613\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3597.96s of the 3597.95s of remaining time.\n",
      "\t0.9695\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3597.83s of the 3597.82s of remaining time.\n",
      "\t0.5418\t = Validation accuracy score\n",
      "\t9.75s\t = Training runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3587.44s of the 3587.43s of remaining time.\n",
      "\t0.8248\t = Validation accuracy score\n",
      "\t7.66s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3579.54s of the 3579.53s of remaining time.\n",
      "\t0.9633\t = Validation accuracy score\n",
      "\t5.86s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3573.58s of the 3573.57s of remaining time.\n",
      "\t0.7963\t = Validation accuracy score\n",
      "\t1.25s\t = Training runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 3572.12s of the 3572.11s of remaining time.\n",
      "\t0.7454\t = Validation accuracy score\n",
      "\t1.17s\t = Training runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3570.75s of the 3570.74s of remaining time.\n",
      "\t0.9674\t = Validation accuracy score\n",
      "\t25.85s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 3544.74s of the 3544.73s of remaining time.\n",
      "\t0.6456\t = Validation accuracy score\n",
      "\t1.26s\t = Training runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 3543.27s of the 3543.25s of remaining time.\n",
      "\t0.6497\t = Validation accuracy score\n",
      "\t1.25s\t = Training runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3541.83s of the 3541.82s of remaining time.\n",
      "\t0.9735\t = Validation accuracy score\n",
      "\t353.18s\t = Training runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 3188.34s of the 3188.33s of remaining time.\n",
      "\t0.4786\t = Validation accuracy score\n",
      "\t22.8s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3164.89s of the 3164.87s of remaining time.\n",
      "\t0.9552\t = Validation accuracy score\n",
      "\t28.79s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Repeating k-fold bagging: 2/20\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3135.24s of the 3135.22s of remaining time.\n",
      "\t0.9613\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3135.23s of the 3135.22s of remaining time.\n",
      "\t0.9695\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3135.23s of the 3135.21s of remaining time.\n",
      "\t0.5397\t = Validation accuracy score\n",
      "\t16.07s\t = Training runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3128.25s of the 3128.24s of remaining time.\n",
      "\t0.8269\t = Validation accuracy score\n",
      "\t14.62s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3121.09s of the 3121.07s of remaining time.\n",
      "\t0.9593\t = Validation accuracy score\n",
      "\t10.81s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3116.05s of the 3116.04s of remaining time.\n",
      "\t0.7963\t = Validation accuracy score\n",
      "\t1.25s\t = Training runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 3116.05s of the 3116.03s of remaining time.\n",
      "\t0.7454\t = Validation accuracy score\n",
      "\t1.17s\t = Training runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3116.04s of the 3116.03s of remaining time.\n",
      "\t0.9532\t = Validation accuracy score\n",
      "\t45.86s\t = Training runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 3095.89s of the 3095.88s of remaining time.\n",
      "\t0.6456\t = Validation accuracy score\n",
      "\t1.26s\t = Training runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 3095.89s of the 3095.87s of remaining time.\n",
      "\t0.6497\t = Validation accuracy score\n",
      "\t1.25s\t = Training runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3095.88s of the 3095.87s of remaining time.\n",
      "\t0.9674\t = Validation accuracy score\n",
      "\t373.94s\t = Training runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 3074.82s of the 3074.81s of remaining time.\n",
      "\t0.5275\t = Validation accuracy score\n",
      "\t72.48s\t = Training runtime\n",
      "\t1.54s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3024.17s of the 3024.16s of remaining time.\n",
      "\t0.945\t = Validation accuracy score\n",
      "\t625.7s\t = Training runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Repeating k-fold bagging: 3/20\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2426.53s of the 2426.52s of remaining time.\n",
      "\t0.9613\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2426.53s of the 2426.51s of remaining time.\n",
      "\t0.9695\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2426.52s of the 2426.51s of remaining time.\n",
      "\t0.5336\t = Validation accuracy score\n",
      "\t22.34s\t = Training runtime\n",
      "\t1.43s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2419.63s of the 2419.62s of remaining time.\n",
      "\t0.8371\t = Validation accuracy score\n",
      "\t153.33s\t = Training runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2280.68s of the 2280.66s of remaining time.\n",
      "\t0.9654\t = Validation accuracy score\n",
      "\t108.19s\t = Training runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2183.14s of the 2183.13s of remaining time.\n",
      "\t0.7963\t = Validation accuracy score\n",
      "\t1.25s\t = Training runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2183.14s of the 2183.13s of remaining time.\n",
      "\t0.7454\t = Validation accuracy score\n",
      "\t1.17s\t = Training runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2183.13s of the 2183.12s of remaining time.\n",
      "\t0.9491\t = Validation accuracy score\n",
      "\t65.92s\t = Training runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2162.92s of the 2162.91s of remaining time.\n",
      "\t0.6456\t = Validation accuracy score\n",
      "\t1.26s\t = Training runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2162.92s of the 2162.9s of remaining time.\n",
      "\t0.6497\t = Validation accuracy score\n",
      "\t1.25s\t = Training runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2162.91s of the 2162.9s of remaining time.\n",
      "\t0.9735\t = Validation accuracy score\n",
      "\t394.39s\t = Training runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 2142.17s of the 2142.16s of remaining time.\n",
      "\t0.556\t = Validation accuracy score\n",
      "\t128.44s\t = Training runtime\n",
      "\t2.37s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2085.35s of the 2085.33s of remaining time.\n",
      "\t0.9532\t = Validation accuracy score\n",
      "\t1206.85s\t = Training runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Repeating k-fold bagging: 4/20\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1503.61s of the 1503.59s of remaining time.\n",
      "\t0.9613\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1503.6s of the 1503.59s of remaining time.\n",
      "\t0.9695\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1503.6s of the 1503.58s of remaining time.\n",
      "\t0.5377\t = Validation accuracy score\n",
      "\t28.52s\t = Training runtime\n",
      "\t1.9s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1496.79s of the 1496.78s of remaining time.\n",
      "\t0.8432\t = Validation accuracy score\n",
      "\t287.26s\t = Training runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1362.65s of the 1362.64s of remaining time.\n",
      "\t0.9633\t = Validation accuracy score\n",
      "\t207.08s\t = Training runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1263.62s of the 1263.61s of remaining time.\n",
      "\t0.7963\t = Validation accuracy score\n",
      "\t1.25s\t = Training runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1263.62s of the 1263.6s of remaining time.\n",
      "\t0.7454\t = Validation accuracy score\n",
      "\t1.17s\t = Training runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1263.61s of the 1263.6s of remaining time.\n",
      "\t0.9613\t = Validation accuracy score\n",
      "\t86.72s\t = Training runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1242.67s of the 1242.66s of remaining time.\n",
      "\t0.6456\t = Validation accuracy score\n",
      "\t1.26s\t = Training runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1242.66s of the 1242.65s of remaining time.\n",
      "\t0.6497\t = Validation accuracy score\n",
      "\t1.25s\t = Training runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1242.66s of the 1242.65s of remaining time.\n",
      "\t0.9776\t = Validation accuracy score\n",
      "\t414.75s\t = Training runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 1222.0s of the 1221.98s of remaining time.\n",
      "\t0.5418\t = Validation accuracy score\n",
      "\t180.61s\t = Training runtime\n",
      "\t3.34s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1168.81s of the 1168.8s of remaining time.\n",
      "\t0.9491\t = Validation accuracy score\n",
      "\t1810.17s\t = Training runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Completed 4/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 564.49s of remaining time.\n",
      "\t0.9857\t = Validation accuracy score\n",
      "\t0.53s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3036.06s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"adult_bsq_ms/\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L2   0.985743       0.364204   415.281328                0.000572           0.528380            2       True         14\n",
      "1            XGBoost_BAG_L1   0.977597       0.251536   414.747516                0.251536         414.747516            1       True         11\n",
      "2     KNeighborsDist_BAG_L1   0.969450       0.112095     0.005432                0.112095           0.005432            1       True          2\n",
      "3           LightGBM_BAG_L1   0.963340       0.248578   207.083251                0.248578         207.083251            1       True          5\n",
      "4     KNeighborsUnif_BAG_L1   0.961303       0.114821     0.006247                0.114821           0.006247            1       True          1\n",
      "5           CatBoost_BAG_L1   0.961303       0.399945    86.722846                0.399945          86.722846            1       True          8\n",
      "6      LightGBMLarge_BAG_L1   0.949084       0.321819  1810.167491                0.321819        1810.167491            1       True         13\n",
      "7         LightGBMXT_BAG_L1   0.843177       0.250611   287.256399                0.250611         287.256399            1       True          4\n",
      "8   RandomForestGini_BAG_L1   0.796334       0.136069     1.254842                0.136069           1.254842            1       True          6\n",
      "9   RandomForestEntr_BAG_L1   0.745418       0.129876     1.166046                0.129876           1.166046            1       True          7\n",
      "10    ExtraTreesEntr_BAG_L1   0.649695       0.126378     1.246250                0.126378           1.246250            1       True         10\n",
      "11    ExtraTreesGini_BAG_L1   0.645621       0.130910     1.255851                0.130910           1.255851            1       True          9\n",
      "12    NeuralNetMXNet_BAG_L1   0.541752       3.342917   180.613414                3.342917         180.613414            1       True         12\n",
      "13   NeuralNetFastAI_BAG_L1   0.537678       1.904103    28.521812                1.904103          28.521812            1       True          3\n",
      "Number of models trained: 14\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_KNN', 'WeightedEnsembleModel', 'StackerEnsembleModel_TabularNeuralNet', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_LGB'}\n",
      "Bagging used: True  (with 4 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])                    :   4 | ['Recommended IND', 'Positive Feedback Count', 'Division Name', 'Department Name']\n",
      "('category', ['text_as_category'])  :   3 | ['Title', 'Review Text', 'Rating']\n",
      "('int', [])                         :   2 | ['Clothing ID', 'Age']\n",
      "('int', ['binned', 'text_special']) :  52 | ['Title.char_count', 'Title.word_count', 'Title.capital_ratio', 'Title.lower_ratio', 'Title.special_ratio', ...]\n",
      "('int', ['text_ngram'])             : 182 | ['__nlp__.about', '__nlp__.all', '__nlp__.also', '__nlp__.am', '__nlp__.an', ...]\n",
      "Plot summary of models saved to file: adult_bsq_ms/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Inference time:\n",
    "test_data = TabularDataset('./datasets/Womens-clothing-E-CommerceReviews-test.csv')  # another Pandas DataFrame\n",
    "y_test = test_data[label]\n",
    "test_data = test_data.drop(labels=[label], axis=1)  # delete labels from test data since we wouldn't have them in practice\n",
    "print(test_data.head())\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loaded data from: ./datasets/Womens-clothing-E-CommerceReviews-test.csv | Columns = 10 / 10 | Rows = 1689 -> 1689\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Clothing ID  Age                   Title  \\\n",
      "0          863   65             Thin & soft   \n",
      "1          863   42            Poor quality   \n",
      "2         1024   34               Run small   \n",
      "3          831   48  Super cute peasant top   \n",
      "4         1121   29         A wrinkled mess   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Review Text  \\\n",
      "0                                                                                                                                                The knit is thin.  it's more for a chilly spring or warm fall day.  but, it's not see-through, although a bit light weight.\\n\\nthe style if figure-flattering and fits tts.  i am short and i found the sleeves, length perfect.  so if you are tall, you \"might\" find this shorter in the arms or body on you.\\n\\ni bought the purple and it's a great color.  love it!   \n",
      "1                                                                                                                                                                                 Love the design of the t-shirt but the quality is poor in my opinion. i got the white t-shirt and the material is so fragile i can see it tearing or being prone to rips after only a few wears. for the price i thought the quality is not up to par. the white t-shirt is see through but with a nude camisole underneath it is fine.   \n",
      "2  These are cool jeans to have in a mound of typical denim jeans i have in my closet and these are like a thorwback of the 60s/70s made with modern, high quality denim. this is my first pair of 7 for all mankind denim, so i can't reference how they fit to their other jeans. however, based on typical pants sizing with other brands at retailer, these pants do run smaller than other brands, especially in the waist area. i ended up buying my size but clearly a diet will be in my near future because they   \n",
      "3                                                                                                                                                                                                                                                                                                                                  This is a super cute peasant top. super light weight and perfect for summer, looks good with jeans or shorts, perfect for summer, spring, or fall. colors are super pretty and bright.   \n",
      "4                                                                                                               I love anything orange- when i saw this coat online, i ordered it as i loved all the features. the features of the coat are fun- however the coat came all bunched up in the package. i let it hang for a couple of days but the wrinkles were awful and even steaming and an iron would not take the creases away. i tried the coat on - the buckles were poorly made. i ended up returning this jacket.   \n",
      "\n",
      "  Rating Recommended IND Positive Feedback Count   Division Name  \\\n",
      "0      5               1                       0  General Petite   \n",
      "1      3               0                       0  General Petite   \n",
      "2      4               1                       0         General   \n",
      "3      5               1                       2         General   \n",
      "4      1               0                       1         General   \n",
      "\n",
      "  Department Name  \n",
      "0            Tops  \n",
      "1            Tops  \n",
      "2         Bottoms  \n",
      "3            Tops  \n",
      "4         Jackets  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "predictor = TabularPredictor.load(save_path)  # Unnecessary, we reload predictor just to demonstrate how to load previously-trained predictor from file\n",
    "y_pred = predictor.predict(test_data)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Labels cannot contain missing (nan) values. Found 3 missing label values.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3422da716462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabularPredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Unnecessary, we reload predictor just to demonstrate how to load previously-trained predictor from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mperf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauxiliary_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Env/auto_glucon/lib/python3.6/site-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mevaluate_predictions\u001b[0;34m(self, y_true, y_pred, silent, auxiliary_metrics, detailed_report)\u001b[0m\n\u001b[1;32m    949\u001b[0m         \"\"\"\n\u001b[1;32m    950\u001b[0m         return self._learner.evaluate_predictions(y_true=y_true, y_pred=y_pred, silent=silent,\n\u001b[0;32m--> 951\u001b[0;31m                                                   auxiliary_metrics=auxiliary_metrics, detailed_report=detailed_report)\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mleaderboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_pareto_frontier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Env/auto_glucon/lib/python3.6/site-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mevaluate_predictions\u001b[0;34m(self, y_true, y_pred, silent, auxiliary_metrics, detailed_report)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_class_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mQUANTILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Env/auto_glucon/lib/python3.6/site-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36m_validate_class_labels\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mnull_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnull_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Labels cannot contain missing (nan) values. Found {null_count} missing label values.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMULTICLASS\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_pred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0my_unique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Labels cannot contain missing (nan) values. Found 3 missing label values."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print('Accuracy = {:.2f}%'.format(perf[\"accuracy\"] * 100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy = 83.49%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "test_data.tail()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       0          1       2             3   4                   5  \\\n",
       "9764  30    Private  151868           9th   5  Married-civ-spouse   \n",
       "9765  32  State-gov  104509       HS-grad   9            Divorced   \n",
       "9766  22    Private  187592  Some-college  10       Never-married   \n",
       "9767  32    Private   49539  Some-college  10       Never-married   \n",
       "9768  25    Private  102476     Bachelors  13       Never-married   \n",
       "\n",
       "                    6              7      8       9     10  11  12  \\\n",
       "9764     Craft-repair        Husband  White    Male      0   0  40   \n",
       "9765    Other-service  Not-in-family  White  Female      0   0  25   \n",
       "9766  Exec-managerial  Not-in-family  White    Male      0   0  30   \n",
       "9767    Other-service  Not-in-family  White  Female   3674   0  40   \n",
       "9768  Farming-fishing      Own-child  White    Male  27828   0  50   \n",
       "\n",
       "                 13  \n",
       "9764  United-States  \n",
       "9765  United-States  \n",
       "9766  United-States  \n",
       "9767  United-States  \n",
       "9768  United-States  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9764</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>151868</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9765</th>\n",
       "      <td>32</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>104509</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>187592</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9767</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>49539</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>3674</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9768</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>102476</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>27828</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('auto_glucon': venv)"
  },
  "interpreter": {
   "hash": "8cbcbecefa271004e6582b9d6d4515a215f41598e734b38ac4197b8836b69e1c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}